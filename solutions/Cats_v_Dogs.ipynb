{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v55rWlQehzL"
      },
      "source": [
        "## Training with a Larger Dataset - Cats and Dogs\n",
        "\n",
        "In the previous lab you trained a classifier with a horses-v-humans dataset. You saw that despite getting great training results, when you tried to do classification with real images, there were many errors, due primarily to overfitting -- where the network  does very well with data that it has previously seen, but poorly with data it hasn't!\n",
        "\n",
        "In this lab you'll look at a real, and very large dataset, and see the impact this has to avoid overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dn-6c02VmqiN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sd9dQWa23aj",
        "outputId": "0dbcae09-dd06-4b44-ff48-2340ba7a1bca"
      },
      "outputs": [],
      "source": [
        "# If the URL doesn't work, visit https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n",
        "# And right click on the 'Download Manually' link to get a new URL to the dataset\n",
        "\n",
        "# Note: This is a very large dataset and will take time to download\n",
        "import urllib.request \n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "#if not os.path.exists(\"../datasets/cats-and-dogs.zip\") :\n",
        " #   print(\"dowload dataset\")\n",
        "  #  url = \"https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\"\n",
        "   # urllib.request.urlretrieve(url, '../datasets/cats-and-dogs.zip')\n",
        "if not os.path.exists(\"../datasets/cats-and-dogs\") :\n",
        "    zip_ref = zipfile.ZipFile('../datasets/cats-and-dogs.zip', 'r')\n",
        "    zip_ref.extractall('../datasets/cats-and-dogs')\n",
        "    zip_ref.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "F-QkLjxpmyK2"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    #os.mkdir('../datasets/cats-and-dogs/PetImages/')\n",
        "    os.mkdir('../datasets/cats-and-dogs/PetImages/training')\n",
        "    os.mkdir('../datasets/cats-and-dogs/PetImages/testing')\n",
        "    os.mkdir('../datasets/cats-and-dogs/PetImages/training/cats')\n",
        "    os.mkdir('../datasets/cats-and-dogs/PetImages/training/dogs')\n",
        "    os.mkdir('../datasets/cats-and-dogs/PetImages/testing/cats')\n",
        "    os.mkdir('../datasets/cats-and-dogs/PetImages/testing/dogs')\n",
        "except OSError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM851ZmN28J3",
        "outputId": "4596193e-8164-4fb8-b1b4-e98dbbefa85d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12501\n",
            "12501\n"
          ]
        }
      ],
      "source": [
        "print(len(os.listdir('../datasets/cats-and-dogs/PetImages/Cat/')))\n",
        "print(len(os.listdir('../datasets/cats-and-dogs/PetImages/Dog/')))\n",
        "\n",
        "# Expected Output:\n",
        "# 12501\n",
        "# 12501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvSODo0f9LaU",
        "outputId": "c2640aae-5410-431c-f065-fd1a52c18f7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "666.jpg is zero length, so ignoring.\n",
            "11702.jpg is zero length, so ignoring.\n"
          ]
        }
      ],
      "source": [
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "    files = []\n",
        "    for filename in os.listdir(SOURCE):\n",
        "        file = SOURCE + filename\n",
        "        if os.path.getsize(file) > 0:\n",
        "            files.append(filename)\n",
        "        else:\n",
        "            print(filename + \" is zero length, so ignoring.\")\n",
        "\n",
        "    training_length = int(len(files) * SPLIT_SIZE)\n",
        "    testing_length = int(len(files) - training_length)\n",
        "    shuffled_set = random.sample(files, len(files))\n",
        "    training_set = shuffled_set[0:training_length]\n",
        "    testing_set = shuffled_set[-testing_length:]\n",
        "\n",
        "    for filename in training_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TRAINING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "    for filename in testing_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TESTING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "\n",
        "CAT_SOURCE_DIR = \"../datasets/cats-and-dogs/PetImages/Cat/\"\n",
        "TRAINING_CATS_DIR = \"../datasets/cats-and-dogs/PetImages/training/cats/\"\n",
        "TESTING_CATS_DIR = \"../datasets/cats-and-dogs/PetImages/testing/cats/\"\n",
        "DOG_SOURCE_DIR = \"../datasets/cats-and-dogs/PetImages/Dog/\"\n",
        "TRAINING_DOGS_DIR = \"../datasets/cats-and-dogs/PetImages/training/dogs/\"\n",
        "TESTING_DOGS_DIR = \"../datasets/cats-and-dogs/PetImages/testing/dogs/\"\n",
        "\n",
        "split_size = .9\n",
        "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
        "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n",
        "\n",
        "# Expected output\n",
        "# 666.jpg is zero length, so ignoring\n",
        "# 11702.jpg is zero length, so ignoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwHXFhVG3786",
        "outputId": "22af40f5-21d4-4099-e49c-8c789520cb83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11250\n",
            "11250\n",
            "1250\n",
            "1250\n"
          ]
        }
      ],
      "source": [
        "print(len(os.listdir('../datasets/cats-and-dogs/PetImages//training/cats/')))\n",
        "print(len(os.listdir('../datasets/cats-and-dogs/PetImages//training/dogs/')))\n",
        "print(len(os.listdir('../datasets/cats-and-dogs/PetImages//testing/cats/')))\n",
        "print(len(os.listdir('../datasets/cats-and-dogs/PetImages//testing/dogs/')))\n",
        "\n",
        "# Expected output:\n",
        "# 11250\n",
        "# 11250\n",
        "# 1250\n",
        "# 1250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BQrav4anTmj",
        "outputId": "f40f72be-62c9-4e62-f981-d9160c5ecfdd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\luca.widmer.NYP.000\\Anaconda3\\envs\\uk259\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQrZfVgz4j2g",
        "outputId": "580b70bd-0163-4d3c-a403-5d0ced5dc6e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 24741 images belonging to 2 classes.\n",
            "Found 4743 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "TRAINING_DIR = \"../datasets/cats-and-dogs/PetImages//training/\"\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
        "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
        "                                                    batch_size=250,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))\n",
        "\n",
        "VALIDATION_DIR = \"../datasets/cats-and-dogs/PetImages//testing/\"\n",
        "validation_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
        "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
        "                                                              batch_size=250,\n",
        "                                                              class_mode='binary',\n",
        "                                                              target_size=(150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 22498 images belonging to 2 classes.\n",
        "# Found 2500 images belonging to 2 classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qE1G6JB4fMn",
        "outputId": "823c1df0-01b8-42f1-ef83-e89ff2a95baa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            " 6/90 [=>............................] - ETA: 2:30 - loss: 2.2108 - acc: 0.5147"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\luca.widmer.NYP.000\\Anaconda3\\envs\\uk259\\lib\\site-packages\\PIL\\TiffImagePlugin.py:819: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90/90 [==============================] - 172s 2s/step - loss: 0.7592 - acc: 0.5995 - val_loss: 0.5778 - val_acc: 0.7000\n",
            "Epoch 2/15\n",
            "90/90 [==============================] - 177s 2s/step - loss: 0.5903 - acc: 0.6883 - val_loss: 0.5545 - val_acc: 0.7313\n",
            "Epoch 3/15\n",
            "90/90 [==============================] - 178s 2s/step - loss: 0.5310 - acc: 0.7286 - val_loss: 0.4395 - val_acc: 0.7973\n",
            "Epoch 4/15\n",
            "90/90 [==============================] - 178s 2s/step - loss: 0.4945 - acc: 0.7590 - val_loss: 0.4389 - val_acc: 0.7867\n",
            "Epoch 5/15\n",
            "90/90 [==============================] - 186s 2s/step - loss: 0.4487 - acc: 0.7853 - val_loss: 0.4035 - val_acc: 0.8173\n",
            "Epoch 6/15\n",
            "90/90 [==============================] - 181s 2s/step - loss: 0.4180 - acc: 0.8073 - val_loss: 0.3824 - val_acc: 0.8287\n",
            "Epoch 7/15\n",
            "90/90 [==============================] - 178s 2s/step - loss: 0.3822 - acc: 0.8254 - val_loss: 0.3041 - val_acc: 0.8753\n",
            "Epoch 8/15\n",
            "90/90 [==============================] - 173s 2s/step - loss: 0.3494 - acc: 0.8429 - val_loss: 0.3450 - val_acc: 0.8407\n",
            "Epoch 9/15\n",
            "90/90 [==============================] - 169s 2s/step - loss: 0.3165 - acc: 0.8601 - val_loss: 0.2456 - val_acc: 0.9020\n",
            "Epoch 10/15\n",
            "90/90 [==============================] - 205s 2s/step - loss: 0.2882 - acc: 0.8749 - val_loss: 0.2591 - val_acc: 0.9020\n",
            "Epoch 11/15\n",
            "90/90 [==============================] - 173s 2s/step - loss: 0.2465 - acc: 0.8970 - val_loss: 0.2124 - val_acc: 0.9327\n",
            "Epoch 12/15\n",
            "90/90 [==============================] - 163s 2s/step - loss: 0.2129 - acc: 0.9144 - val_loss: 0.1400 - val_acc: 0.9493\n",
            "Epoch 13/15\n",
            "90/90 [==============================] - 167s 2s/step - loss: 0.1795 - acc: 0.9279 - val_loss: 0.1669 - val_acc: 0.9487\n",
            "Epoch 14/15\n",
            "90/90 [==============================] - 182s 2s/step - loss: 0.1427 - acc: 0.9455 - val_loss: 0.1007 - val_acc: 0.9700\n",
            "Epoch 15/15\n",
            "90/90 [==============================] - 170s 2s/step - loss: 0.1193 - acc: 0.9546 - val_loss: 0.0722 - val_acc: 0.9853\n"
          ]
        }
      ],
      "source": [
        "# Note that this may take some time.\n",
        "history = model.fit(train_generator, epochs=15, steps_per_epoch=90,\n",
        "                    validation_data=validation_generator, validation_steps=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MWZrJN4-65RC"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mC:\\Users\\LUCAWI~1.000\\AppData\\Local\\Temp/ipykernel_15716/3756843453.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# sets for each training epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#-----------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['acc']\n",
        "val_acc=history.history['val_acc']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "# Desired output. Charts with training and validation metrics. No crash :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqL6FYUrtXpf"
      },
      "outputs": [],
      "source": [
        "# Here's a codeblock just for fun. You should be able to upload an image here \n",
        "# and have it classified without crashing\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a dog\")\n",
        "  else:\n",
        "    print(fn + \" is a cat\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Lab6-Cats-v-Dogs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.9 ('uk259')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "04ef47e14afcc12bc8afdbb05faf5df96ba6e8d3916c9b18b282210d98731075"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
